<!--
Copyright 2019 Google LLC. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================
-->

<!doctype html>

<head>
  <title> Salty Wet Man
</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="../shared/tfjs-examples.css" />
  <link rel="stylesheet" href="./style.css" />
</head>

<body>
  <div class="tfjs-example-container">
    <section class='title-area'>
      <h1>Salty Wet Man: Visualize Convnet Internals using TensorFlow.js</h1>
    </section>

    <section>
      <p class='section-head'>Description</p>
      <p>
        Not Suitable for Work (NSFW) image classification using Keras and Tensorflow machine learning tools.
        Demonstrates  techniques of visualizing
        the internal workings of a convolutional neural network (convnet)
        in TensorFlow.js.

        <ul>
          <li>
            Finding what convolutional layers' filters are sensitive to after
            training. Then calculating maximally-activating NSFW input image for
            convolutional filters through gradient ascent in the input space.
          </li>
          <li>
          Classifier.
        Defining NSFW material is subjective and the task of identifying these images is non-trivial.
        Identification into two categories
            [SFW] positively trained for neutral images that are safe for work.
            [NSFW] negatively trained for pornographic images involving sexually explicit images, acts, or drawings.
          </li>
          <li>
            Getting the internal activation of a convnet by usng the
            functional model API of TensorFlow.js.
          </li>
          <li>
            Finding which part of an input image is most relevant to the
            classification decision made by a convnet using the gradient-based class activation map (CAM)
            approach.
          </li>
        </ul>
      </p>
    </section>

    <section>
      <p class='section-head image-result-heading'>
        NSFW input image and classification result
      </p>

      <div id="image-result"></div>

      <p class='section-head'>Image visualization</p>

      <div>
        <span>What to visualize:</span>
        <select id="viz-type">
          <option value="activation">Filter activation</option>
          <option value="filters">Maximally-activating input images</option>
          <option value="cam">Class activation map (CAM)</option>
        </select>
      </div>

      <div id="viz-section"></div>
    </section>

    <script src="index.js"></script>
  </div>
</body>
